{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 start\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File SL_mobnet_equalpop.csv does not exist: 'SL_mobnet_equalpop.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-69be0bbe4fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mpop_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_agloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mmob_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SL_mobnet_equalpop.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mmob_net\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmob_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File SL_mobnet_equalpop.csv does not exist: 'SL_mobnet_equalpop.csv'"
     ]
    }
   ],
   "source": [
    "#simulate the model of Corey for epidemics with different latent times\n",
    "\n",
    "    #a) agent-based model\n",
    "\n",
    "        #agents are in five compartments: SEI(A)IR (2 I compartments: asymptomatic, symptomatic)\n",
    "        #S are susceptible, E are infected but in the latency state, I are infected and infectious and R recovered.\n",
    "        #S+E+R move freely on a spatial network (2d lattice)\n",
    "        #I do not move\n",
    "        \n",
    "        #S+I->I+E with prob beta\n",
    "        #E->I after a certain latent time T_l (deterministic or from a distribution)\n",
    "        #I->R after a certain infectious time T_i (deterministic or from a distribution)\n",
    "        \n",
    "    #b) network minimal model for comparison of basic mechanism\n",
    "        \n",
    "        #metapopulation-like model\n",
    "        #interaction network is a sum of powers of the mobility network in a) up to power T_l\n",
    "        #Time is in generations, where a genera1tion is takes a time of T_l\n",
    "        \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.random import binomial,seed\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import erlang\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(12345)\n",
    "seed(seed=12345)\n",
    "#a) ABM\n",
    "\n",
    "#initialize\n",
    "\n",
    "## space and demographics\n",
    "\n",
    "l=15 # side of the rectangular lattice\n",
    "l2=10 # side of rectangular lattice\n",
    "n_agloc=300 # number of agents in each location initially\n",
    "\n",
    "N_loc=l*l2 # number of locations\n",
    "N_agents=n_agloc*l*l2# total number of agents\n",
    "G=nx.grid_2d_graph(l,l2) # network for the spatial substrate\n",
    "\n",
    "## epidemic model parameters\n",
    "\n",
    "m=1 # number of steps per day\n",
    "\n",
    "alpha=0.1 #moving probability\n",
    "beta=0.2 # force of infection\n",
    "mu_recover=0.1 # recovery rate\n",
    "delta=0.001 #flight prob; not currently used\n",
    "perc_asymp=0.5 # % asymptomatic\n",
    "\n",
    "\n",
    "exp=2 #exponent for the gravity law for mobility\n",
    "\n",
    "\n",
    "\n",
    "T_l=5 # incubation period\n",
    "alpha_step=1-np.power((1-alpha),1.0/float(m)) # probability of moving\n",
    "beta_step=beta/(m) # probability of disease transmission\n",
    "mu_step=1-np.power((1-mu_recover),1.0/float(m)) # probability of recovery\n",
    "gamma=0 # increase/decrease on moving probability for infectious individuals\n",
    "\n",
    "# other parameters\n",
    "\n",
    "end_time=500\n",
    "\n",
    "#choose how the incubation periods are chosen from an Erlang distribution\n",
    "# parameters of the distribution: k=shape, mu=scale; \n",
    "                                #T_l=k*mu (mean), sigma^2=k*mu^2 (variance);\n",
    "                                #k=(T_l/sigma)^2, mu=sigma^2/T_l\n",
    "    #1- constant variance sigma_0^2 across different T_l's\n",
    "    #2- constant k (not 1, because with k=1 we have an exponential distribution),\n",
    "    #sigma increases with T_l \n",
    "\n",
    "erlang_type=2\n",
    "sigma_0=2 # will use only in case erlang_type=1 (constant variance)\n",
    "k=10 # will use only in case erlang_type=2 (constant k)\n",
    "if erlang_type==1:\n",
    "    a=T_l/sigma_0\n",
    "    mu=sigma_0/a\n",
    "    k=a*a\n",
    "elif erlang_type==2:\n",
    "    mu=T_l/k\n",
    "    \n",
    "rv=erlang(k,scale=mu)\n",
    "\n",
    "## give locations to all agents\n",
    "\n",
    "Nruns=1\n",
    "\n",
    "\n",
    "peak_height=list()\n",
    "peak_time=list()\n",
    "start_time=list()\n",
    "inf_per_day=list()\n",
    "day_50=list()\n",
    "day_100=list()\n",
    "day_150=list()\n",
    "day_200=list()\n",
    "\n",
    "\n",
    "for irun in range(Nruns):\n",
    "    print (Nruns-irun,'start')\n",
    "\n",
    "    loc=dict() # location of each agent\n",
    "    agents=dict() # agents in each location\n",
    "    S=dict() # S agents in each location\n",
    "    E=dict() # E agents in each location\n",
    "    IAS=dict() # asymptomatic I agents in each location\n",
    "    IS=dict() # symptomatic I agents in each location\n",
    "    R=dict() # R agents in each location\n",
    "    day_count=dict()\n",
    "\n",
    "\n",
    "\n",
    "    peak_height.append(np.zeros((l,l2)))\n",
    "    peak_time.append(np.zeros((l,l2)))\n",
    "    start_time.append(np.zeros((l,l2)))\n",
    "    day_50.append(np.zeros((l,l2)))\n",
    "    day_100.append(np.zeros((l,l2)))\n",
    "    day_150.append(np.zeros((l,l2)))\n",
    "    day_200.append(np.zeros((l,l2)))\n",
    "    time_series=np.zeros((end_time+2,l*l2))\n",
    "    active_agents=np.zeros((end_time+2,l*l2))\n",
    "\n",
    "\n",
    "    k=0\n",
    "    for i in range(l):\n",
    "        for j in range(l2):\n",
    "            iloc=(i,j)\n",
    "            agents[iloc]=set()\n",
    "            S[iloc]=set()\n",
    "            E[iloc]=set()\n",
    "            IAS[iloc]=set()\n",
    "            IS[iloc]=set()\n",
    "            R[iloc]=set()\n",
    "            day_count[iloc]=set()\n",
    "            for j in range(n_agloc):\n",
    "                loc[k]=iloc\n",
    "                agents[iloc].add(k)\n",
    "                S[iloc].add(k)\n",
    "                k+=1\n",
    "    \n",
    "    pop_size=np.zeros((l,l2))\n",
    "    for x in range(l):\n",
    "        for y in range(l2):\n",
    "            pop_size[x][y]=n_agloc\n",
    "    \n",
    "    mob_net = pd.read_csv('SL_mobnet_equalpop.csv', sep=',',header=0)\n",
    "    mob_net=mob_net.values\n",
    "\n",
    "            \n",
    "    state=np.zeros(N_agents) # epidemic state of each agent\n",
    "    inf_time=np.zeros(N_agents) # time at which agent became E\n",
    "    ## initial condition for the epidemics\n",
    "\n",
    "    iloc=(int(l/2-0.5),int(l2/2)) # the place where we start having a percentage perc of E individuals \n",
    "    perc=0.05 # percentage of E agents initially in location iloc; the rest of agents are S\n",
    "\n",
    "\n",
    "    for agent in random.sample(agents[iloc],int(perc*(n_agloc))):\n",
    "        state[agent]=1\n",
    "        tt=rv.rvs(1)\n",
    "        #tt=np.random.uniform(0,10)\n",
    "        #print (tt)\n",
    "        inf_time[agent]=tt\n",
    "        #inf_time[agent]=T_l # change here the time T_l for one from a distribution to get variation on it\n",
    "        S[iloc].remove(agent)\n",
    "        E[iloc].add(agent)\n",
    "        \n",
    "    ###SAVE INITIAL CONDITION/PRINT WHATEVER/PLOT WHATEVER\n",
    "\n",
    "\n",
    "    #data structure to save all epidemic curves\n",
    "\n",
    "    epi_curves=dict()\n",
    "    #for ix in range(l):\n",
    "    #    epi_curves[ix]=dict()\n",
    "     #   for iy in range(l):\n",
    "      #      epi_curves[ix][iy]=list()\n",
    "\n",
    "    i_plot=np.zeros((l,l2))\n",
    "    #for ix in range(l):\n",
    "     #   for iy in range(l):\n",
    "      #      kk=float(len(I[(ix,iy)]))/float(len(agents[(ix,iy)]))\n",
    "       #     i_plot[ix][iy]=kk\n",
    "        #    epi_curves[ix][iy].append(kk)\n",
    "    #fig=plt.figure()\n",
    "    ##plt.subplot(221,title='$P$ only space')\n",
    "    #plt.imshow(i_plot,vmin=0, vmax=1, cmap='jet')\n",
    "    #fig.savefig('a_%.3i.png' % 0,bbox_inches='tight')\n",
    "    ##plt.show()\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    I_tot=0\n",
    "    #print(0,I_tot)\n",
    "    ## start the epidemics\n",
    "\n",
    "    locations=G.nodes()\n",
    "    for time in range(end_time):\n",
    "        for k in range(m):\n",
    "            # first move\n",
    "            for iloc in locations:\n",
    "                #print(time,iloc,len(agents[iloc]))\n",
    "                fro=iloc[0]+l*iloc[1] \n",
    "                #print(iloc,fro)\n",
    "                N_move=binomial(len(agents[iloc])-len(IS[iloc]),alpha) # number of agents moving\n",
    "                agents_move=random.sample(agents[iloc]-IS[iloc],N_move) # set of agents moving\n",
    "                #N_flight=binomial(len(agents_move),delta)\n",
    "                #agents_flight=random.sample(agents_move,N_flight)\n",
    "                #agents_flight=set(agents_flight)\n",
    "                agents_move=set(agents_move)\n",
    "                #agents_diff=set()\n",
    "                #agents_diff=agents_move-agents_flight\n",
    "                # places where they will move\n",
    "                #p=mob_net[fro][:]\n",
    "                #print(p)\n",
    "                dest=np.random.choice(np.arange(l*l2),size=N_move,replace=True,p=mob_net[fro][:])\n",
    "                i=0\n",
    "                for agent in agents_move:\n",
    "                    to=dest[i]\n",
    "                    xdest=to-l*int(to/l)\n",
    "                    ydest=int(to/l)\n",
    "                    #jloc=random.sample(G.neighbors(iloc),1)[0]\n",
    "                    jloc=(xdest,ydest)\n",
    "                    loc[agent]=jloc\n",
    "                    agents[iloc].remove(agent)\n",
    "                    agents[jloc].add(agent)\n",
    "                    if state[agent]==0:\n",
    "                        S[iloc].remove(agent)\n",
    "                        S[jloc].add(agent)\n",
    "                    elif state[agent]==1:\n",
    "                        E[iloc].remove(agent)\n",
    "                        E[jloc].add(agent)\n",
    "                    else:\n",
    "                        R[iloc].remove(agent)\n",
    "                        R[jloc].add(agent)\n",
    "                    i+=1\n",
    "                #for agent in agents_flight:\n",
    "                    #jloc=random.choice(locations)\n",
    "                    #loc[agent]=jloc\n",
    "                    #agents[iloc].remove(agent)\n",
    "                    #agents[jloc].add(agent)\n",
    "                    #if state[agent]==0:\n",
    "                        #S[iloc].remove(agent)\n",
    "                        #S[jloc].add(agent)\n",
    "                    #elif state[agent]==1:\n",
    "                        #E[iloc].remove(agent)\n",
    "                        #E[jloc].add(agent)\n",
    "                    #else:\n",
    "                        #R[iloc].remove(agent)\n",
    "                        #R[jloc].add(agent)\n",
    "                ###HAVE TO INCLUDE THE TELEPORTATIONS FOR I IN CASE GAMMA!=0\n",
    "                #N_move=binomial(len(IS[iloc]),alpha*gamma)\n",
    "                #dest=np.random.choice(np.arange(l*l2),size=N_move,replace=True,p=mob_net[fro][:])\n",
    "                #i=0\n",
    "                #for agent in random.sample(IS[iloc],N_move):state\n",
    "                    #jloc=random.sample(G.neighbors(iloc),1)[0]\n",
    "                    #to=dest[i]\n",
    "                    #xdest=to-l*int(to/l)\n",
    "                    #ydest=int(to/l)\n",
    "                    #jloc=(xdest,ydest)\n",
    "                    #loc[agent]=jloc\n",
    "                    #agents[iloc].remove(agent)\n",
    "                    #agents[jloc].add(agent)\n",
    "                    #IS[iloc].remove(agent)\n",
    "                    #IS[jloc].add(agent)\n",
    "            # second infection dynamics\n",
    "            col=0\n",
    "            for iloc in locations:\n",
    "                beta_step=beta/len(agents[iloc])\n",
    "                #print(iloc)\n",
    "                N_inf=binomial(len(S[iloc]),1.0-np.power(1.0-beta_step,(len(IS[iloc]+len(IAS[iloc])))))\n",
    "                N_rem_IS=binomial(len(IS[iloc]),mu_step)\n",
    "                N_rem_IAS=binomial(len(IAS[iloc]),mu_step)\n",
    "                for agent in random.sample(S[iloc],N_inf):\n",
    "                    state[agent]=1\n",
    "                    tt=rv.rvs(1)\n",
    "                    #tt=np.random.uniform(0,10)\n",
    "                    inf_time[agent]=time+tt\n",
    "                    #inf_time[agent]=time+T_l # change here the time T_l for one from a distribution to get variation on it\n",
    "                    S[iloc].remove(agent)\n",
    "                    E[iloc].add(agent)\n",
    "                    day_count[iloc].add(agent)\n",
    "                for agent in random.sample(IS[iloc],N_rem_IS):\n",
    "                    state[agent]=3\n",
    "                    IS[iloc].remove(agent)\n",
    "                    R[iloc].add(agent)\n",
    "                for agent in random.sample(IAS[iloc],N_rem_IAS):\n",
    "                    state[agent]=3\n",
    "                    IAS[iloc].remove(agent)\n",
    "                    R[iloc].add(agent)\n",
    "                a=set(E[iloc])\n",
    "                New_inf=0\n",
    "                for agent in a:\n",
    "                    if inf_time[agent]<=time:\n",
    "                        state[agent]=2\n",
    "                        E[iloc].remove(agent)\n",
    "                        asymp = binomial(1,perc_asymp)\n",
    "                        if asymp==1: \n",
    "                            IAS[iloc].add(agent)\n",
    "                        else: \n",
    "                            IS[iloc].add(agent)\n",
    "                        New_inf+=1\n",
    "                time_series[0][col]=iloc[0]\n",
    "                time_series[1][col]=iloc[1]\n",
    "                time_series[time+2][col]=New_inf\n",
    "                active_agents[0][col]=iloc[0]\n",
    "                active_agents[1][col]=iloc[1]\n",
    "                active_agents[time+2][col]=len(IS[iloc]) + len(IAS[iloc])\n",
    "                col+=1\n",
    "        I_tot=0\n",
    "        for iloc in locations:\n",
    "            I_tot+=len(IS[iloc])\n",
    "            I_tot+=len(IAS[iloc])\n",
    "        inf_per_day.append(I_tot)\n",
    "        #print(irun,time+1,I_tot)\n",
    "        for ix in range(l):\n",
    "            for iy in range(l2):\n",
    "                if float(len(agents[(ix,iy)]))>0:\n",
    "                    kk=float(len(I[(ix,iy)]))/float(len(agents[(ix,iy)]))\n",
    "                else:\n",
    "                    kk=0 \n",
    "                i_plot[ix][iy]=kk\n",
    "                #epi_curves[ix][iy].append(kk)\n",
    "                if kk > peak_height[irun][ix][iy]:\n",
    "                    peak_height[irun][ix][iy]=kk\n",
    "                    peak_time[irun][ix][iy]=time+1\n",
    "                if start_time[irun][ix][iy]==0:\n",
    "                    if len(I[(ix,iy)])>0:\n",
    "                        start_time[irun][ix][iy]=time+1\n",
    "                if time==50:\n",
    "                    day_50[irun][ix][iy]=len(day_count[ix,iy])\n",
    "                if time==100:\n",
    "                    day_100[irun][ix][iy]=len(day_count[ix,iy])\n",
    "                if time==150:\n",
    "                    day_150[irun][ix][iy]=len(day_count[ix,iy])\n",
    "                if time==200:\n",
    "                    day_200[irun][ix][iy]=len(day_count[ix,iy])\n",
    "\n",
    "            #fig=plt.figure()\n",
    "        #plt.subplot(221,title='$P$ only space')\n",
    "        plt.imshow(i_plot,vmin=0, vmax=0.5, cmap='jet')\n",
    "        plt.colorbar()\n",
    "        fig.savefig('a_%.3i.png' % (time+1),bbox_inches='tight')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "    np.savetxt('inf_per_day'+str(T_l)+'_'+str(irun)+'.csv', inf_per_day)\n",
    "    np.savetxt('time_series'+str(T_l)+'_'+str(irun)+'.csv', time_series,delimiter=',')\n",
    "    np.savetxt('active_agents'+str(T_l)+'_'+str(irun)+'.csv', active_agents,delimiter=',')\n",
    "\n",
    "\n",
    "    os.system('mencoder mf://a_*.png -mf w=800:h=600:fps=10:type=png -ovc lavc -lavcopts vcodec=mpeg4:mbd=2:trell -oac copy -o latent_times_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'_'+str(irun)+'.avi')\n",
    "\n",
    "    os.system('rm a_*.png')\n",
    "    print(Nruns-irun,'end')\n",
    "\n",
    "\n",
    "    #fig=plt.figure()\n",
    "    ##plt.subplot(221,title='$P$ only space')\n",
    "    #plt.imshow(peak_height[irun],vmin=0, vmax=1, cmap='jet')\n",
    "    #fig.savefig('peak_height_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'_'+str(irun)+'.png',bbox_inches='tight')\n",
    "   \n",
    "    ##plt.show()\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "    #fig=plt.figure()\n",
    "    ##plt.subplot(221,title='$P$ only space')\n",
    "    #plt.imshow(peak_time[irun],vmin=0,vmax=end_time,cmap='jet')\n",
    "    #fig.savefig('peak_time_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'_'+str(irun)+'.png',bbox_inches='tight')\n",
    "    ##plt.show()\n",
    "    #plt.close()\n",
    "\n",
    "    #av_peak_time=np.zeros((l))\n",
    "    #norm_av_peak_time=np.zeros((l))\n",
    "    #a=int(l/2)\n",
    "    #for ix in range(l):\n",
    "        #for iy in range(l):\n",
    "            #d=abs(ix-a)+abs(iy-a)\n",
    "            #av_peak_time[d]+=float(peak_time[irun][ix][iy])\n",
    "            #norm_av_peak_time[d]+=1.0\n",
    "\n",
    "    #for i in range(l):\n",
    "        ##print(av_peak_time[i],norm_av_peak_time[i],av_peak_time[i]/norm_av_peak_time[i])\n",
    "        #av_peak_time[i]=av_peak_time[i]/norm_av_peak_time[i]\n",
    "\n",
    "    #fig=plt.figure()\n",
    "    ##plt.subplot(221,title='$P$ only space')\n",
    "    #plt.plot(av_peak_time)\n",
    "    #fig.savefig('peak_time_d_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'_'+str(irun)+'.png',bbox_inches='tight')\n",
    "    ##plt.show()\n",
    "    #plt.close()\n",
    "    \n",
    "#figure av_peak_height 2d\n",
    "\n",
    "#np.savetxt('mob_net'+str(irun)+'.csv', mob_net,delimiter=',')\n",
    "\n",
    "av_peak_height=np.zeros((l,l2))\n",
    "\n",
    "for ix in range(l):\n",
    "    for iy in range(l2):\n",
    "        for irun in range(Nruns):\n",
    "            av_peak_height[ix][iy]+=peak_height[irun][ix][iy]/float(Nruns)\n",
    "\n",
    "#fig=plt.figure()\n",
    "#plt.subplot(221,title='$P$ only space')\n",
    "#plt.imshow(av_peak_height,vmin=0, vmax=1, cmap='jet')\n",
    "#plt.colorbar()\n",
    "#fig.savefig('av_peak_height_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'.png',bbox_inches='tight')\n",
    "#np.savetxt('av_peak_height'+str(T_l)+'.csv', av_peak_height, delimiter=\",\")\n",
    "#plt.show()\n",
    "#plt.close()\n",
    "\n",
    "#figure av_peak_time 2d\n",
    "\n",
    "\n",
    "av_peak_time=np.zeros((l,l2))\n",
    "av_start_time=np.zeros((l,l2))\n",
    "av_day_50=np.zeros((l,l2))\n",
    "av_day_100=np.zeros((l,l2))\n",
    "av_day_150=np.zeros((l,l2))\n",
    "av_day_200=np.zeros((l,l2))\n",
    "\n",
    "\n",
    "for ix in range(l):\n",
    "    for iy in range(l2):\n",
    "        for irun in range(Nruns):\n",
    "            av_peak_time[ix][iy]+=peak_time[irun][ix][iy]/float(Nruns)\n",
    "            av_start_time[ix][iy]+=start_time[irun][ix][iy]/float(Nruns)\n",
    "            av_day_50[ix][iy]+=day_50[irun][ix][iy]/float(Nruns)\n",
    "            av_day_100[ix][iy]+=day_100[irun][ix][iy]/float(Nruns)\n",
    "            av_day_150[ix][iy]+=day_150[irun][ix][iy]/float(Nruns)\n",
    "            av_day_200[ix][iy]+=day_200[irun][ix][iy]/float(Nruns)\n",
    "\n",
    "#fig=plt.figure()\n",
    "#plt.subplot(221,title='$P$ only space')\n",
    "#plt.imshow(av_peak_time,vmin=0,vmax=end_time,cmap='jet')\n",
    "#plt.colorbar()\n",
    "#fig.savefig('av_peak_time_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'.png',bbox_inches='tight')\n",
    "np.savetxt('av_peak_time'+str(T_l)+'.csv', av_peak_time, delimiter=\",\")\n",
    "np.savetxt('av_start_time'+str(T_l)+'.csv', av_start_time, delimiter=\",\") \n",
    "#np.savetxt('av_day_50_'+str(T_l)+'.csv', av_day_50, delimiter=\",\") \n",
    "#np.savetxt('av_day_100_'+str(T_l)+'.csv', av_day_100, delimiter=\",\") \n",
    "#np.savetxt('av_day_150_'+str(T_l)+'.csv', av_day_150, delimiter=\",\") \n",
    "#np.savetxt('av_day_200_'+str(T_l)+'.csv', av_day_200, delimiter=\",\") \n",
    "#plt.show()\n",
    "plt.close()\n",
    "\n",
    "#figure av_peak_time as a function of distance\n",
    "\n",
    "maxdist=int(3.0*l/4.0)\n",
    "\n",
    "av_peak_time=np.zeros((maxdist)) #!!!!  BE CAREFUL\n",
    "av2_peak_time=np.zeros((maxdist))\n",
    "norm_av_peak_time=np.zeros((maxdist))\n",
    "a=int(l/2)\n",
    "for ix in range(l):\n",
    "    for iy in range(l2):\n",
    "        d=abs(ix-a)+abs(iy-a)\n",
    "        if d<maxdist:\n",
    "            #print(d)\n",
    "            for irun in range(Nruns):\n",
    "                kk=float(peak_time[irun][ix][iy])\n",
    "                av_peak_time[d]+=kk\n",
    "                av2_peak_time[d]+=kk*kk\n",
    "                norm_av_peak_time[d]+=1.0\n",
    "\n",
    "for i in range(maxdist):\n",
    "    #print(av_peak_time[i],av2_peak_time[i])\n",
    "    av_peak_time[i]=av_peak_time[i]/norm_av_peak_time[i]\n",
    "    av2_peak_time[i]=av2_peak_time[i]/norm_av_peak_time[i]\n",
    "    av2_peak_time[i]=np.sqrt(abs(av2_peak_time[i]-av_peak_time[i]*av_peak_time[i]))\n",
    "\n",
    "#fig=plt.figure()\n",
    "#plt.subplot(221,title='$P$ only space')\n",
    "#plt.ylim(0,400)\n",
    "#plt.errorbar(np.arange(maxdist),av_peak_time,yerr=av2_peak_time)\n",
    "#fig.savefig('av_peak_time_d_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'.png',bbox_inches='tight')\n",
    "#plt.show()\n",
    "#plt.close()\n",
    "\n",
    "\n",
    "#PIECE OF CODE FOR DOING A PIECEWISE LINEAR APPROXIMATION\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "def piecewise_linear(x, x0, y0, k1, k2):\n",
    "    return np.piecewise(x, [x < x0, x > x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n",
    "\n",
    "\n",
    "##do the fits for piecewise linear fits (for peak times)\n",
    "\n",
    "x=np.linspace(0, maxdist, maxdist)\n",
    "y=av_peak_time\n",
    "\n",
    "p , e = optimize.curve_fit(piecewise_linear, x, y)\n",
    "print(p)\n",
    "\n",
    "\n",
    "xd = np.linspace(0, maxdist, 100)\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(xd, piecewise_linear(xd, *p))\n",
    "plt.show()\n",
    "\n",
    "k1=0.0\n",
    "k1_2=0.0\n",
    "\n",
    "k2=0.0\n",
    "k2_2=0.0\n",
    "\n",
    "x0=0.0\n",
    "x0_2=0.0\n",
    "\n",
    "\n",
    "x=np.linspace(0, maxdist, maxdist)\n",
    "\n",
    "for irun in range(Nruns):\n",
    "    #x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15], dtype=float)\n",
    "    #figure av_peak_time as a function of distance\n",
    "\n",
    "    av_peak_time=np.zeros((maxdist)) #!!!!  BE CAREFUL\n",
    "    #av2_peak_time=np.zeros((l+1))\n",
    "    norm_av_peak_time=np.zeros((maxdist))\n",
    "    a=int(l/2)\n",
    "    for ix in range(l):\n",
    "        for iy in range(l2):\n",
    "            d=abs(ix-a)+abs(iy-a)\n",
    "            if d<maxdist:\n",
    "                kk=float(peak_time[irun][ix][iy])\n",
    "                av_peak_time[d]+=kk\n",
    "                #av2_peak_time[d]+=kk*kk\n",
    "                norm_av_peak_time[d]+=1.0\n",
    "\n",
    "    for i in range(maxdist):\n",
    "        #print(av_peak_time[i],av2_peak_time[i])\n",
    "        #if norm_av_peak_time[i]==0.0:\n",
    "            #print(l,i,irun)\n",
    "        #elif norm_av_peak_time[i]=='NaN':\n",
    "            #print(l,i,irun)\n",
    "        #elif norm_av_peak_time[i]=='inf':\n",
    "            #print(l,i,irun)\n",
    "        #print(irun,l,i,av_peak_time[i],norm_av_peak_time[i])\n",
    "        av_peak_time[i]=av_peak_time[i]/norm_av_peak_time[i]\n",
    "        #av2_peak_time[i]=av2_peak_time[i]/norm_av_peak_time[i]\n",
    "        #av2_peak_time[i]=np.sqrt(abs(av2_peak_time[i]-av_peak_time[i]*av_peak_time[i]))\n",
    "        \n",
    "    y=av_peak_time\n",
    "    #y = np.array([5, 7, 9, 11, 13, 15, 28.92, 42.81, 56.7, 70.59, 84.47, 98.36, 112.25, 126.14, 140.03])\n",
    "\n",
    "    p , e = optimize.curve_fit(piecewise_linear, x, y)\n",
    "    \n",
    "    x0+=p[0]\n",
    "    x0_2+=p[0]*p[0]\n",
    "    \n",
    "    k1+=p[2]\n",
    "    k1_2+=p[2]*p[2]\n",
    "    \n",
    "    k2+=p[3]\n",
    "    k2_2+=p[3]*p[3]\n",
    "    \n",
    "    \n",
    "    xd = np.linspace(0, maxdist, 100)\n",
    "    plt.plot(x, y, \"o\")\n",
    "    plt.plot(xd, piecewise_linear(xd, *p))\n",
    "    plt.show()\n",
    "    #pl.plot(xd, piecewise_linear(xd, *p))\n",
    "\n",
    "a=1/float(Nruns)\n",
    "x0=x0*a\n",
    "x0_2=x0_2*a\n",
    "x0_2=x0*x0-x0_2\n",
    "\n",
    "k1=k1*a\n",
    "k1_2=k1_2*a\n",
    "k1_2=k1*k1-k1_2\n",
    "\n",
    "k2=k2*a\n",
    "k2_2=k2_2*a\n",
    "k2_2=k2*k2-k2_2\n",
    "\n",
    "fout=open('spatial_spread_l_'+str(l)+'_erlang_'+str(erlang_type)+'_Tl_'+str(T_l)+'.dat','w')\n",
    "fout.write('%i %f %f %f %f %f %f \\n' % (T_l,x0,x0_2,k1,k1_2,k2,k2_2))\n",
    "fout.close()\n",
    "\n",
    "\n",
    "\n",
    "###fig=plt.figure()\n",
    "\n",
    "###for nplot in range(N_loc):\n",
    "    ###plt.subplot(l,l,nplot+1)\n",
    "    ###ix=nplot-l*int(nplot/l)\n",
    "    ###iy=int(nplot/l)\n",
    "    ###plt.plot(epi_curves[ix][iy])\n",
    "    ###frame=plt.gca()\n",
    "    ###frame.axes.get_xaxis().set_visible(False)\n",
    "    ###frame.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "####plt.show()\n",
    "###fig.savefig('epi_curves_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'.png',bbox_inches='tight')\n",
    "###plt.close()\n",
    "\n",
    "#b) network minimal model for comparison of basic mechanism\n",
    "\n",
    "##from numpy import linalg as LA\n",
    "##A=nx.adjacency_matrix(G)\n",
    "\n",
    "##print(A)\n",
    "##print(type(A))\n",
    "##A=A.todense()\n",
    "##A=(1.0-alpha_step)*A/4.0\n",
    "##print(A/4.0)\n",
    "##for i in range(N_loc):\n",
    "    ##A[i][i]=alpha\n",
    "                    \n",
    "                    \n",
    "##print(type(A))\n",
    "##B=LA.matrix_power(A,T_l)\n",
    "##print(B)\n",
    "##print(type(B))f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.random import binomial,seed\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import erlang\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
