{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'grid_2d_grbaph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-eb0c8cdb2c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mN_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m \u001b[0;31m# number of locations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mN_agents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_agloc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN_loc\u001b[0m\u001b[0;31m# total number of agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_2d_grbaph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# network for the spatial substrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m## epidemic model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'grid_2d_grbaph'"
     ]
    }
   ],
   "source": [
    "#simulate the model of Corey for epidemics with different latent times\n",
    "\n",
    "    #a) agent-based model\n",
    "\n",
    "        #agents are in five compartments: SEI(A)IR (2 I compartments: asymptomatic, symptomatic)\n",
    "        #S are susceptible, E are infected but in the latency state, I are infected and infectious and R recovered.\n",
    "        #S+E+R move freely on a spatial network (2d lattice)\n",
    "        #I do not move\n",
    "        \n",
    "        #S+I->I+E with prob beta\n",
    "        #E->I after a certain latent time T_l (deterministic or from a distribution)\n",
    "        #I->R after a certain infectious time T_i (deterministic or from a distribution)\n",
    "        \n",
    "    #b) network minimal model for comparison of basic mechanism\n",
    "        \n",
    "        #metapopulation-like model\n",
    "        #interaction network is a sum of powers of the mobility network in a) up to power T_l\n",
    "        #Time is in generations, where a genera1tion is takes a time of T_l\n",
    "        \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.random import binomial,seed\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import erlang\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(12345)\n",
    "seed(seed=12345)\n",
    "#a) ABM\n",
    "\n",
    "#initialize\n",
    "\n",
    "## space and demographics\n",
    "\n",
    "l=15 # sides of the square lattice\n",
    "n_agloc=300 # number of agents in each location initially\n",
    "\n",
    "N_loc=l*l # number of locations\n",
    "N_agents=n_agloc*N_loc# total number of agents\n",
    "G=nx.grid_2d_grbaph(l,l) # network for the spatial substrate\n",
    "\n",
    "## epidemic model parameters\n",
    "\n",
    "m=1 # number of steps per day\n",
    "\n",
    "alpha_init=0.05 #moving probability\n",
    "beta_init=0.15 # force of infection\n",
    "mu_recover=0.1 # recovery rate\n",
    "delta=0.001 #flight prob; not currently used\n",
    "perc_asymp=0.5 # % asymptomatic\n",
    "\n",
    "t_ld_a=70 #time lockdown announced\n",
    "t_ld_b=75 #time lockdown begins\n",
    "\n",
    "beta_inc=beta_init*2 #beta increase after lockdown announced\n",
    "beta_dec=beta_init*0.5 #beta decrease after lockdown begins\n",
    "\n",
    "alpha_inc=alpha_init*2 #travel increase after lockdown announced\n",
    "alpha_dec=alpha_init*0.1 #travel decrease after lockdown begins\n",
    "\n",
    "exp=2 #exponent for the gravity law for mobility\n",
    "\n",
    "\n",
    "\n",
    "T_l=5 # incubation period\n",
    "#alpha_step=1-np.power((1-alpha),1.0/float(m)) # probability of moving\n",
    "#beta_step=beta/(m) # probability of disease transmission\n",
    "mu_step=1-np.power((1-mu_recover),1.0/float(m)) # probability of recovery\n",
    "gamma=0 # increase/decrease on moving probability for infectious individuals\n",
    "\n",
    "# other parameters\n",
    "\n",
    "end_time=300\n",
    "\n",
    "#choose how the incubation periods are chosen from an Erlang distribution\n",
    "# parameters of the distribution: k=shape, mu=scale; \n",
    "                                #T_l=k*mu (mean), sigma^2=k*mu^2 (variance);\n",
    "                                #k=(T_l/sigma)^2, mu=sigma^2/T_l\n",
    "    #1- constant variance sigma_0^2 across different T_l's\n",
    "    #2- constant k (not 1, because with k=1 we have an exponential distribution),\n",
    "    #sigma increases with T_l \n",
    "\n",
    "erlang_type=2\n",
    "sigma_0=2 # will use only in case erlang_type=1 (constant variance)\n",
    "k=10 # will use only in case erlang_type=2 (constant k)\n",
    "if erlang_type==1:\n",
    "    a=T_l/sigma_0\n",
    "    mu=sigma_0/a\n",
    "    k=a*a\n",
    "elif erlang_type==2:\n",
    "    mu=T_l/k\n",
    "    \n",
    "rv=erlang(k,scale=mu)\n",
    "\n",
    "## give locations to all agents\n",
    "\n",
    "Nruns=1\n",
    "\n",
    "\n",
    "peak_height=list()\n",
    "peak_time=list()\n",
    "start_time=list()\n",
    "inf_per_day=list()\n",
    "day_50=list()\n",
    "day_100=list()\n",
    "day_150=list()\n",
    "day_200=list()\n",
    "\n",
    "\n",
    "for irun in range(Nruns):\n",
    "    print (Nruns-irun,'start')\n",
    "\n",
    "    loc=dict() # location of each agent\n",
    "    agents=dict() # agents in each location\n",
    "    S=dict() # S agents in each location\n",
    "    E=dict() # E agents in each location\n",
    "    IAS=dict() # asymptomatic I agents in each location\n",
    "    IS=dict() # symptomatic I agents in each location\n",
    "    R=dict() # R agents in each location\n",
    "    day_count=dict()\n",
    "\n",
    "\n",
    "\n",
    "    peak_height.append(np.zeros((l,l)))\n",
    "    peak_time.append(np.zeros((l,l)))\n",
    "    start_time.append(np.zeros((l,l)))\n",
    "    day_50.append(np.zeros((l,l)))\n",
    "    day_100.append(np.zeros((l,l)))\n",
    "    day_150.append(np.zeros((l,l)))\n",
    "    day_200.append(np.zeros((l,l)))\n",
    "    time_series=np.zeros((end_time+2,l*l))\n",
    "    active_agents=np.zeros((end_time+2,l*l))\n",
    "\n",
    "\n",
    "    k=0\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            iloc=(i,j)\n",
    "            agents[iloc]=set()\n",
    "            S[iloc]=set()\n",
    "            E[iloc]=set()\n",
    "            IAS[iloc]=set()\n",
    "            IS[iloc]=set()\n",
    "            R[iloc]=set()\n",
    "            day_count[iloc]=set()\n",
    "            for j in range(n_agloc):\n",
    "                loc[k]=iloc\n",
    "                agents[iloc].add(k)\n",
    "                S[iloc].add(k)\n",
    "                k+=1\n",
    "    \n",
    "    pop_size=np.zeros((l,l))\n",
    "    for x in range(l):\n",
    "        for y in range(l):\n",
    "            pop_size[x][y]=n_agloc\n",
    "    \n",
    "    mob_net=np.zeros((l*l,l*l))\n",
    "\n",
    "    for fro in range(l*l):\n",
    "        x1=fro-l*int(fro/l)\n",
    "        y1=int(fro/l)\n",
    "        norm=0.0\n",
    "        for to in range(l*l):\n",
    "            if fro!=to:\n",
    "                x2=to-l*int(to/l)\n",
    "                y2=int(to/l)\n",
    "                d=np.sqrt((x1-x2)*(x1-x2)+(y1-y2)*(y1-y2))\n",
    "                a=1.0/np.power(d,exp)\n",
    "                mob_net[fro][to]=a\n",
    "                norm+=a\n",
    "        for to in range(l*l):\n",
    "            if fro!=to:\n",
    "                mob_net[fro][to]=mob_net[fro][to]/norm\n",
    "\n",
    "            \n",
    "    state=np.zeros(N_agents) # epidemic state of each agent\n",
    "    inf_time=np.zeros(N_agents) # time at which agent became E\n",
    "    ## initial condition for the epidemics\n",
    "\n",
    "    start_iloc=(7,7) # the place where we start having a percentage perc of E individuals \n",
    "    perc=0.05 # percentage of E agents initially in location iloc; the rest of agents are S\n",
    "\n",
    "\n",
    "    for agent in random.sample(agents[start_iloc],int(perc*(n_agloc))):\n",
    "        state[agent]=1\n",
    "        tt=rv.rvs(1)\n",
    "        #tt=np.random.uniform(0,10)\n",
    "        #print (tt)\n",
    "        inf_time[agent]=tt\n",
    "        #inf_time[agent]=T_l # change here the time T_l for one from a distribution to get variation on it\n",
    "        S[start_iloc].remove(agent)\n",
    "        E[start_iloc].add(agent)\n",
    "        \n",
    "    ###SAVE INITIAL CONDITION/PRINT WHATEVER/PLOT WHATEVER\n",
    "\n",
    "\n",
    "    #data structure to save all epidemic curves\n",
    "\n",
    "    epi_curves=dict()\n",
    "    #for ix in range(l):\n",
    "    #    epi_curves[ix]=dict()\n",
    "     #   for iy in range(l):\n",
    "      #      epi_curves[ix][iy]=list()\n",
    "\n",
    "    i_plot=np.zeros((l,l))\n",
    "    #for ix in range(l):\n",
    "     #   for iy in range(l):\n",
    "      #      kk=float(len(I[(ix,iy)]))/float(len(agents[(ix,iy)]))\n",
    "       #     i_plot[ix][iy]=kk\n",
    "        #    epi_curves[ix][iy].append(kk)\n",
    "    #fig=plt.figure()\n",
    "    ##plt.subplot(221,title='$P$ only space')\n",
    "    #plt.imshow(i_plot,vmin=0, vmax=1, cmap='jet')\n",
    "    #fig.savefig('a_%.3i.png' % 0,bbox_inches='tight')\n",
    "    ##plt.show()\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    I_tot=0\n",
    "    #print(0,I_tot)\n",
    "    ## start the epidemics\n",
    "\n",
    "    locations=G.nodes()\n",
    "    for time in range(end_time):\n",
    "        for k in range(m):\n",
    "            # first move\n",
    "            for iloc in locations:\n",
    "                if iloc==start_iloc:\n",
    "                    if time >= t_ld_a:\n",
    "                        if time <t_ld_b:  \n",
    "                            alpha=alpha_inc\n",
    "                            beta=beta_inc \n",
    "                        elif time>=t_ld_b:\n",
    "                            alpha=alpha_dec\n",
    "                            beta=beta_dec\n",
    "                        else:\n",
    "                            alpha=alpha_init\n",
    "                            beta=beta_init\n",
    "                else:\n",
    "                    alpha=alpha_init\n",
    "                    beta=beta_init\n",
    "                #print(time,iloc,len(agents[iloc]))\n",
    "                fro=iloc[0]+l*iloc[1] \n",
    "                #print(iloc,fro)\n",
    "                N_move=binomial(len(agents[iloc])-len(IS[iloc]),alpha) # number of agents moving\n",
    "                agents_move=random.sample(agents[iloc]-IS[iloc],N_move) # set of agents moving\n",
    "                #N_flight=binomial(len(agents_move),delta)\n",
    "                #agents_flight=random.sample(agents_move,N_flight)\n",
    "                #agents_flight=set(agents_flight)\n",
    "                agents_move=set(agents_move)\n",
    "                #agents_diff=set()\n",
    "                #agents_diff=agents_move-agents_flight\n",
    "                # places where they will move\n",
    "                #p=mob_net[fro][:]\n",
    "                #print(p)\n",
    "                dest=np.random.choice(np.arange(l*l),size=N_move,replace=True,p=mob_net[fro][:])\n",
    "                i=0\n",
    "                for agent in agents_move:\n",
    "                    to=dest[i]\n",
    "                    xdest=to-l*int(to/l)\n",
    "                    ydest=int(to/l)\n",
    "                    #jloc=random.sample(G.neighbors(iloc),1)[0]\n",
    "                    jloc=(xdest,ydest)\n",
    "                    loc[agent]=jloc\n",
    "                    agents[iloc].remove(agent)\n",
    "                    agents[jloc].add(agent)\n",
    "                    if state[agent]==0:\n",
    "                        S[iloc].remove(agent)\n",
    "                        S[jloc].add(agent)\n",
    "                    elif state[agent]==1:\n",
    "                        E[iloc].remove(agent)\n",
    "                        E[jloc].add(agent)\n",
    "                    elif state[agent]==2:\n",
    "                        IAS[iloc].remove(agent)\n",
    "                        IAS[jloc].add(agent)\n",
    "                    else:\n",
    "                        R[iloc].remove(agent)\n",
    "                        R[jloc].add(agent)\n",
    "                    i+=1\n",
    "                #for agent in agents_flight:\n",
    "                    #jloc=random.choice(locations)\n",
    "                    #loc[agent]=jloc\n",
    "                    #agents[iloc].remove(agent)\n",
    "                    #agents[jloc].add(agent)\n",
    "                    #if state[agent]==0:\n",
    "                        #S[iloc].remove(agent)\n",
    "                        #S[jloc].add(agent)\n",
    "                    #elif state[agent]==1:\n",
    "                        #E[iloc].remove(agent)\n",
    "                        #E[jloc].add(agent)\n",
    "                    #else:\n",
    "                        #R[iloc].remove(agent)\n",
    "                        #R[jloc].add(agent)\n",
    "                ###HAVE TO INCLUDE THE TELEPORTATIONS FOR I IN CASE GAMMA!=0\n",
    "                #N_move=binomial(len(IS[iloc]),alpha*gamma)\n",
    "                #dest=np.random.choice(np.arange(l*l),size=N_move,replace=True,p=mob_net[fro][:])\n",
    "                #i=0\n",
    "                #for agent in random.sample(IS[iloc],N_move):state\n",
    "                    #jloc=random.sample(G.neighbors(iloc),1)[0]\n",
    "                    #to=dest[i]\n",
    "                    #xdest=to-l*int(to/l)\n",
    "                    #ydest=int(to/l)\n",
    "                    #jloc=(xdest,ydest)\n",
    "                    #loc[agent]=jloc\n",
    "                    #agents[iloc].remove(agent)\n",
    "                    #agents[jloc].add(agent)\n",
    "                    #IS[iloc].remove(agent)\n",
    "                    #IS[jloc].add(agent)\n",
    "            # second infection dynamics\n",
    "            col=0\n",
    "            for iloc in locations:\n",
    "                beta_step=beta/len(agents[iloc])\n",
    "                #print(iloc)\n",
    "                tot_num_inf = len(IS[iloc])+len(IAS[iloc])\n",
    "                N_inf=binomial(len(S[iloc]),1.0-np.power(1.0-beta_step,tot_num_inf))\n",
    "                N_rem_IS=binomial(len(IS[iloc]),mu_step)\n",
    "                N_rem_IAS=binomial(len(IAS[iloc]),mu_step)\n",
    "                for agent in random.sample(S[iloc],N_inf):\n",
    "                    state[agent]=1\n",
    "                    tt=rv.rvs(1)\n",
    "                    #tt=np.random.uniform(0,10)\n",
    "                    inf_time[agent]=time+tt\n",
    "                    #inf_time[agent]=time+T_l # change here the time T_l for one from a distribution to get variation on it\n",
    "                    S[iloc].remove(agent)\n",
    "                    E[iloc].add(agent)\n",
    "                    day_count[iloc].add(agent)\n",
    "                for agent in random.sample(IS[iloc],N_rem_IS):\n",
    "                    state[agent]=3\n",
    "                    IS[iloc].remove(agent)\n",
    "                    R[iloc].add(agent)\n",
    "                for agent in random.sample(IAS[iloc],N_rem_IAS):\n",
    "                    state[agent]=3\n",
    "                    IAS[iloc].remove(agent)\n",
    "                    R[iloc].add(agent)\n",
    "                a=set(E[iloc])\n",
    "                New_inf=0\n",
    "                for agent in a:\n",
    "                    if inf_time[agent]<=time:\n",
    "                        state[agent]=2\n",
    "                        E[iloc].remove(agent)\n",
    "                        asymp = binomial(1,perc_asymp)\n",
    "                        if asymp==1: \n",
    "                            IAS[iloc].add(agent)\n",
    "                        else: \n",
    "                            IS[iloc].add(agent)\n",
    "                        New_inf+=1\n",
    "                time_series[0][col]=iloc[0]\n",
    "                time_series[1][col]=iloc[1]\n",
    "                time_series[time+2][col]=New_inf\n",
    "                active_agents[0][col]=iloc[0]\n",
    "                active_agents[1][col]=iloc[1]\n",
    "                active_agents[time+2][col]=len(IS[iloc]) + len(IAS[iloc])\n",
    "                col+=1\n",
    "        I_tot=0\n",
    "        for iloc in locations:\n",
    "            I_tot+=len(IS[iloc])\n",
    "            I_tot+=len(IAS[iloc])\n",
    "        inf_per_day.append(I_tot)\n",
    "        #print(irun,time+1,I_tot)\n",
    "        #for ix in range(l):\n",
    "            #for iy in range(l):\n",
    "                #if float(len(agents[(ix,iy)]))>0:\n",
    "                    #tot_num_inf_i = len(IS[(ix,iy)]) + len(IAS[(ix,iy)])\n",
    "                    #kk=float(tot_num_inf_i)/float(len(agents[(ix,iy)]))\n",
    "                #else:\n",
    "                    #kk=0 \n",
    "                #i_plot[ix][iy]=kk\n",
    "                #epi_curves[ix][iy].append(kk)\n",
    "                #if kk > peak_height[irun][ix][iy]:\n",
    "                    #peak_height[irun][ix][iy]=kk\n",
    "                    #peak_time[irun][ix][iy]=time+1\n",
    "                #if start_time[irun][ix][iy]==0:\n",
    "                    #if len(I[(ix,iy)])>0:\n",
    "                        #start_time[irun][ix][iy]=time+1\n",
    "                #if time==50:\n",
    "                    #day_50[irun][ix][iy]=len(day_count[ix,iy])\n",
    "                #if time==100:\n",
    "                    #day_100[irun][ix][iy]=len(day_count[ix,iy])\n",
    "                #if time==150:\n",
    "                    #day_150[irun][ix][iy]=len(day_count[ix,iy])\n",
    "                #if time==200:\n",
    "                    #day_200[irun][ix][iy]=len(day_count[ix,iy])\n",
    "\n",
    "            #fig=plt.figure()\n",
    "        #plt.subplot(221,title='$P$ only space')\n",
    "        #plt.imshow(i_plot,vmin=0, vmax=0.5, cmap='jet')\n",
    "        #plt.colorbar()\n",
    "        #fig.savefig('a_%.3i.png' % (time+1),bbox_inches='tight')\n",
    "        #plt.show()\n",
    "        #plt.close()\n",
    "    #np.savetxt('inf_per_day'+str(T_l)+'_'+str(irun)+'.csv', inf_per_day)\n",
    "    np.savetxt('time_series'+str(T_l)+'_'+str(irun)+'.csv', time_series,delimiter=',')\n",
    "    np.savetxt('active_agents'+str(T_l)+'_'+str(irun)+'.csv', active_agents,delimiter=',')\n",
    "\n",
    "\n",
    "    os.system('mencoder mf://a_*.png -mf w=800:h=600:fps=10:type=png -ovc lavc -lavcopts vcodec=mpeg4:mbd=2:trell -oac copy -o latent_times_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'_'+str(irun)+'.avi')\n",
    "\n",
    "    os.system('rm a_*.png')\n",
    "    print(Nruns-irun,'end')\n",
    "\n",
    "\n",
    "    #fig=plt.figure()\n",
    "    ##plt.subplot(221,title='$P$ only space')\n",
    "    #plt.imshow(peak_height[irun],vmin=0, vmax=1, cmap='jet')\n",
    "    #fig.savefig('peak_height_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'_'+str(irun)+'.png',bbox_inches='tight')\n",
    "   \n",
    "    ##plt.show()\n",
    "    #plt.close()\n",
    "\n",
    "\n",
    "    #fig=plt.figure()\n",
    "    ##plt.subplot(221,title='$P$ only space')\n",
    "    #plt.imshow(peak_time[irun],vmin=0,vmax=end_time,cmap='jet')\n",
    "    #fig.savefig('peak_time_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'_'+str(irun)+'.png',bbox_inches='tight')\n",
    "    ##plt.show()\n",
    "    #plt.close()\n",
    "\n",
    "    #av_peak_time=np.zeros((l))\n",
    "    #norm_av_peak_time=np.zeros((l))\n",
    "    #a=int(l/2)\n",
    "    #for ix in range(l):\n",
    "        #for iy in range(l):\n",
    "            #d=abs(ix-a)+abs(iy-a)\n",
    "            #av_peak_time[d]+=float(peak_time[irun][ix][iy])\n",
    "            #norm_av_peak_time[d]+=1.0\n",
    "\n",
    "    #for i in range(l):\n",
    "        ##print(av_peak_time[i],norm_av_peak_time[i],av_peak_time[i]/norm_av_peak_time[i])\n",
    "        #av_peak_time[i]=av_peak_time[i]/norm_av_peak_time[i]\n",
    "\n",
    "    #fig=plt.figure()\n",
    "    ##plt.subplot(221,title='$P$ only space')\n",
    "    #plt.plot(av_peak_time)\n",
    "    #fig.savefig('peak_time_d_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'_'+str(irun)+'.png',bbox_inches='tight')\n",
    "    ##plt.show()\n",
    "    #plt.close()\n",
    "    \n",
    "#figure av_peak_height 2d\n",
    "\n",
    "#np.savetxt('mob_net'+str(irun)+'.csv', mob_net,delimiter=',')\n",
    "\n",
    "av_peak_height=np.zeros((l,l))\n",
    "\n",
    "for ix in range(l):\n",
    "    for iy in range(l):\n",
    "        for irun in range(Nruns):\n",
    "            av_peak_height[ix][iy]+=peak_height[irun][ix][iy]/float(Nruns)\n",
    "\n",
    "#fig=plt.figure()\n",
    "#plt.subplot(221,title='$P$ only space')\n",
    "#plt.imshow(av_peak_height,vmin=0, vmax=1, cmap='jet')\n",
    "#plt.colorbar()\n",
    "#fig.savefig('av_peak_height_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'.png',bbox_inches='tight')\n",
    "#np.savetxt('av_peak_height'+str(T_l)+'.csv', av_peak_height, delimiter=\",\")\n",
    "#plt.show()\n",
    "#plt.close()\n",
    "\n",
    "#figure av_peak_time 2d\n",
    "\n",
    "\n",
    "av_peak_time=np.zeros((l,l))\n",
    "av_start_time=np.zeros((l,l))\n",
    "av_day_50=np.zeros((l,l))\n",
    "av_day_100=np.zeros((l,l))\n",
    "av_day_150=np.zeros((l,l))\n",
    "av_day_200=np.zeros((l,l))\n",
    "\n",
    "\n",
    "for ix in range(l):\n",
    "    for iy in range(l):\n",
    "        for irun in range(Nruns):\n",
    "            av_peak_time[ix][iy]+=peak_time[irun][ix][iy]/float(Nruns)\n",
    "            av_start_time[ix][iy]+=start_time[irun][ix][iy]/float(Nruns)\n",
    "            av_day_50[ix][iy]+=day_50[irun][ix][iy]/float(Nruns)\n",
    "            av_day_100[ix][iy]+=day_100[irun][ix][iy]/float(Nruns)\n",
    "            av_day_150[ix][iy]+=day_150[irun][ix][iy]/float(Nruns)\n",
    "            av_day_200[ix][iy]+=day_200[irun][ix][iy]/float(Nruns)\n",
    "\n",
    "#fig=plt.figure()\n",
    "#plt.subplot(221,title='$P$ only space')\n",
    "#plt.imshow(av_peak_time,vmin=0,vmax=end_time,cmap='jet')\n",
    "#plt.colorbar()\n",
    "#fig.savefig('av_peak_time_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'.png',bbox_inches='tight')\n",
    "#np.savetxt('av_peak_time'+str(T_l)+'.csv', av_peak_time, delimiter=\",\")\n",
    "#np.savetxt('av_start_time'+str(T_l)+'.csv', av_start_time, delimiter=\",\") \n",
    "#np.savetxt('av_day_50_'+str(T_l)+'.csv', av_day_50, delimiter=\",\") \n",
    "#np.savetxt('av_day_100_'+str(T_l)+'.csv', av_day_100, delimiter=\",\") \n",
    "#np.savetxt('av_day_150_'+str(T_l)+'.csv', av_day_150, delimiter=\",\") \n",
    "#np.savetxt('av_day_200_'+str(T_l)+'.csv', av_day_200, delimiter=\",\") \n",
    "#plt.show()\n",
    "#plt.close()\n",
    "\n",
    "#figure av_peak_time as a function of distance\n",
    "\n",
    "maxdist=int(3.0*l/4.0)\n",
    "\n",
    "av_peak_time=np.zeros((maxdist)) #!!!!  BE CAREFUL\n",
    "av2_peak_time=np.zeros((maxdist))\n",
    "norm_av_peak_time=np.zeros((maxdist))\n",
    "a=int(l/2)\n",
    "for ix in range(l):\n",
    "    for iy in range(l):\n",
    "        d=abs(ix-a)+abs(iy-a)\n",
    "        if d<maxdist:\n",
    "            #print(d)\n",
    "            for irun in range(Nruns):\n",
    "                kk=float(peak_time[irun][ix][iy])\n",
    "                av_peak_time[d]+=kk\n",
    "                av2_peak_time[d]+=kk*kk\n",
    "                norm_av_peak_time[d]+=1.0\n",
    "\n",
    "for i in range(maxdist):\n",
    "    #print(av_peak_time[i],av2_peak_time[i])\n",
    "    av_peak_time[i]=av_peak_time[i]/norm_av_peak_time[i]\n",
    "    av2_peak_time[i]=av2_peak_time[i]/norm_av_peak_time[i]\n",
    "    av2_peak_time[i]=np.sqrt(abs(av2_peak_time[i]-av_peak_time[i]*av_peak_time[i]))\n",
    "\n",
    "#fig=plt.figure()\n",
    "#plt.subplot(221,title='$P$ only space')\n",
    "#plt.ylim(0,400)\n",
    "#plt.errorbar(np.arange(maxdist),av_peak_time,yerr=av2_peak_time)\n",
    "#fig.savefig('av_peak_time_d_l_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'.png',bbox_inches='tight')\n",
    "#plt.show()\n",
    "#plt.close()\n",
    "\n",
    "\n",
    "#PIECE OF CODE FOR DOING A PIECEWISE LINEAR APPROXIMATION\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "def piecewise_linear(x, x0, y0, k1, k2):\n",
    "    return np.piecewise(x, [x < x0, x > x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n",
    "\n",
    "\n",
    "##do the fits for piecewise linear fits (for peak times)\n",
    "\n",
    "x=np.linspace(0, maxdist, maxdist)\n",
    "y=av_peak_time\n",
    "\n",
    "p , e = optimize.curve_fit(piecewise_linear, x, y)\n",
    "print(p)\n",
    "\n",
    "\n",
    "xd = np.linspace(0, maxdist, 100)\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(xd, piecewise_linear(xd, *p))\n",
    "plt.show()\n",
    "\n",
    "k1=0.0\n",
    "k1_2=0.0\n",
    "\n",
    "k2=0.0\n",
    "k2_2=0.0\n",
    "\n",
    "x0=0.0\n",
    "x0_2=0.0\n",
    "\n",
    "\n",
    "x=np.linspace(0, maxdist, maxdist)\n",
    "\n",
    "for irun in range(Nruns):\n",
    "    #x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15], dtype=float)\n",
    "    #figure av_peak_time as a function of distance\n",
    "\n",
    "    av_peak_time=np.zeros((maxdist)) #!!!!  BE CAREFUL\n",
    "    #av2_peak_time=np.zeros((l+1))\n",
    "    norm_av_peak_time=np.zeros((maxdist))\n",
    "    a=int(l/2)\n",
    "    for ix in range(l):\n",
    "        for iy in range(l):\n",
    "            d=abs(ix-a)+abs(iy-a)\n",
    "            if d<maxdist:\n",
    "                kk=float(peak_time[irun][ix][iy])\n",
    "                av_peak_time[d]+=kk\n",
    "                #av2_peak_time[d]+=kk*kk\n",
    "                norm_av_peak_time[d]+=1.0\n",
    "\n",
    "    for i in range(maxdist):\n",
    "        #print(av_peak_time[i],av2_peak_time[i])\n",
    "        #if norm_av_peak_time[i]==0.0:\n",
    "            #print(l,i,irun)\n",
    "        #elif norm_av_peak_time[i]=='NaN':\n",
    "            #print(l,i,irun)\n",
    "        #elif norm_av_peak_time[i]=='inf':\n",
    "            #print(l,i,irun)\n",
    "        #print(irun,l,i,av_peak_time[i],norm_av_peak_time[i])\n",
    "        av_peak_time[i]=av_peak_time[i]/norm_av_peak_time[i]\n",
    "        #av2_peak_time[i]=av2_peak_time[i]/norm_av_peak_time[i]\n",
    "        #av2_peak_time[i]=np.sqrt(abs(av2_peak_time[i]-av_peak_time[i]*av_peak_time[i]))\n",
    "        \n",
    "    y=av_peak_time\n",
    "    #y = np.array([5, 7, 9, 11, 13, 15, 28.92, 42.81, 56.7, 70.59, 84.47, 98.36, 112.25, 126.14, 140.03])\n",
    "\n",
    "    p , e = optimize.curve_fit(piecewise_linear, x, y)\n",
    "    \n",
    "    x0+=p[0]\n",
    "    x0_2+=p[0]*p[0]\n",
    "    \n",
    "    k1+=p[2]\n",
    "    k1_2+=p[2]*p[2]\n",
    "    \n",
    "    k2+=p[3]\n",
    "    k2_2+=p[3]*p[3]\n",
    "    \n",
    "    \n",
    "    xd = np.linspace(0, maxdist, 100)\n",
    "    plt.plot(x, y, \"o\")\n",
    "    plt.plot(xd, piecewise_linear(xd, *p))\n",
    "    plt.show()\n",
    "    #pl.plot(xd, piecewise_linear(xd, *p))\n",
    "\n",
    "a=1/float(Nruns)\n",
    "x0=x0*a\n",
    "x0_2=x0_2*a\n",
    "x0_2=x0*x0-x0_2\n",
    "\n",
    "k1=k1*a\n",
    "k1_2=k1_2*a\n",
    "k1_2=k1*k1-k1_2\n",
    "\n",
    "k2=k2*a\n",
    "k2_2=k2_2*a\n",
    "k2_2=k2*k2-k2_2\n",
    "\n",
    "#fout=open('spatial_spread_l_'+str(l)+'_erlang_'+str(erlang_type)+'_Tl_'+str(T_l)+'.dat','w')\n",
    "#fout.write('%i %f %f %f %f %f %f \\n' % (T_l,x0,x0_2,k1,k1_2,k2,k2_2))\n",
    "#fout.close()\n",
    "\n",
    "\n",
    "\n",
    "###fig=plt.figure()\n",
    "\n",
    "###for nplot in range(N_loc):\n",
    "    ###plt.subplot(l,l,nplot+1)\n",
    "    ###ix=nplot-l*int(nplot/l)\n",
    "    ###iy=int(nplot/l)\n",
    "    ###plt.plot(epi_curves[ix][iy])\n",
    "    ###frame=plt.gca()\n",
    "    ###frame.axes.get_xaxis().set_visible(False)\n",
    "    ###frame.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "####plt.show()\n",
    "###fig.savefig('epi_curves_'+str(l)+'_Tl_'+str(T_l)+'_'+str(m)+'.png',bbox_inches='tight')\n",
    "###plt.close()\n",
    "\n",
    "#b) network minimal model for comparison of basic mechanism\n",
    "\n",
    "##from numpy import linalg as LA\n",
    "##A=nx.adjacency_matrix(G)\n",
    "\n",
    "##print(A)\n",
    "##print(type(A))\n",
    "##A=A.todense()\n",
    "##A=(1.0-alpha_step)*A/4.0\n",
    "##print(A/4.0)\n",
    "##for i in range(N_loc):\n",
    "    ##A[i][i]=alpha\n",
    "                    \n",
    "                    \n",
    "##print(type(A))\n",
    "##B=LA.matrix_power(A,T_l)\n",
    "##print(B)\n",
    "##print(type(B))f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
